video_dir: "../Datasets/dev/" #upper leve directory where your datasets are stored
base_model_name: "LanguageBind/Video-LLaVA-7B-hf" 
adapter_name: Null #"mvrdock/Video-LLaVA-7B-natural-2000" #Null, mvrdock/Video-LLaVA-7B-natural
experiment_name: "O3" # corresponds to the folder name like O1,O2,O3 or gravity, etc
output_file_name: "base" 
dataset_type: "intphys" #intphys or inflevel
hf_home: "/w/340/abarroso/huggingface" # for caching
n_frames: 7 # How many frames you skipS
num_workers: 0
prompt: "User: <video>\n Do all objects in the video move without skipping or teleporting through space? Explain why or why not.\nAssistant:" 

# test type and cot only for inflevel
test_type: "COT" # COT, continuos or binary
cot_config:  #Only works if test type is "COT"
  LLM_model_name: "vicgalle/gpt2-open-instruct-v1"
  LLM_prompt: |
                ### Instruction:
                Answer with "yes" or "no" only. If the statement clearly indicates that **an object** skips or teleports, answer "no". If the statement suggests that **all objects** move without skipping or teleporting, answer "yes".
                Statment:
                {llava_output}
                ### Response:\n
experiment_config: #Only use for Inflevel, these are pretty much constant
  gravity:
    fields: ["camera_loc", "cover", "obj", "trial_type"]
  continuity:
    fields: ["camera_loc", "cover", "obj", "trial_type", "dir"]
  solidity:
    fields: ["camera_loc", "cover", "obj", "trial_type"]
  custom:
    fields: ["tbd", "tbd2"]